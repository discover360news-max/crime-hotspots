# Comprehensive Fix Plan - Crime Hotspots Data Quality

**Date:** November 9, 2025
**Approach:** Methodical, layered validation with checks at every step
**Goal:** Production-ready data quality with easy diagnosis of issues

---

## ğŸ¯ Design Principles

1. **Fail Fast, Fail Visible** - Problems should be caught immediately and logged clearly
2. **Validate at Every Layer** - Don't trust data from previous step without validation
3. **Single Responsibility** - Each component does ONE thing well
4. **Traceable** - Every piece of data can be traced back to source
5. **Testable** - Every component has test functions

---

## ğŸ“Š Complete Data Flow with Validation Points

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LAYER 1: RSS Collection                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Input: RSS Feed URLs                                         â”‚
â”‚ Output: Title, URL, Published Date â†’ Raw Articles (status: pending) â”‚
â”‚                                                              â”‚
â”‚ âœ“ Validation 1.1: URL is valid HTTP/HTTPS                   â”‚
â”‚ âœ“ Validation 1.2: Title is not empty                        â”‚
â”‚ âœ“ Validation 1.3: Not duplicate (URL already exists)        â”‚
â”‚ âœ“ Validation 1.4: Published date is valid                   â”‚
â”‚                                                              â”‚
â”‚ âŒ Fail Action: Log error, skip entry, continue             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LAYER 2: Article Text Fetching                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Input: URL from Raw Articles (status: pending)              â”‚
â”‚ Output: Full Text â†’ Raw Articles Column E (status: ready_for_processing) â”‚
â”‚                                                              â”‚
â”‚ âœ“ Validation 2.1: HTTP 200 response                         â”‚
â”‚ âœ“ Validation 2.2: Content length > 200 chars                â”‚
â”‚ âœ“ Validation 2.3: Content contains title keywords (>30% match) â”‚
â”‚ âœ“ Validation 2.4: Content is primarily text (not JS/CSS)    â”‚
â”‚ âœ“ Validation 2.5: Extract from <article> or <div.content>   â”‚
â”‚                                                              â”‚
â”‚ âŒ Fail Action: status = fetch_failed, log reason, retry later â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LAYER 3: Gemini AI Extraction                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Input: Full Text, Title, URL, Published Date                â”‚
â”‚ Output: {crimes: [...], confidence, ambiguities}             â”‚
â”‚                                                              â”‚
â”‚ âœ“ Validation 3.1: Response is valid JSON                    â”‚
â”‚ âœ“ Validation 3.2: crimes is an array                        â”‚
â”‚ âœ“ Validation 3.3: Each crime has required fields            â”‚
â”‚ âœ“ Validation 3.4: source_url matches input URL              â”‚
â”‚ âœ“ Validation 3.5: Confidence score 0-10                     â”‚
â”‚ âœ“ Validation 3.6: Response not truncated                    â”‚
â”‚                                                              â”‚
â”‚ âŒ Fail Action: confidence = 0, ambiguities logged, skip or review â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LAYER 4: Crime Data Validation                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Input: Individual crime object from crimes array            â”‚
â”‚ Output: {valid: boolean, issues: []}                        â”‚
â”‚                                                              â”‚
â”‚ âœ“ Validation 4.1: crime_date is valid YYYY-MM-DD            â”‚
â”‚ âœ“ Validation 4.2: crime_date within 30 days of published    â”‚
â”‚ âœ“ Validation 4.3: crime_type in allowed list                â”‚
â”‚ âœ“ Validation 4.4: area not "Unknown" or too vague           â”‚
â”‚ âœ“ Validation 4.5: headline length 10-200 chars              â”‚
â”‚ âœ“ Validation 4.6: headline keywords in source text          â”‚
â”‚ âœ“ Validation 4.7: source_url matches article URL            â”‚
â”‚ âœ“ Validation 4.8: No non-crime keywords (traffic, policy)   â”‚
â”‚                                                              â”‚
â”‚ âŒ Fail Action: Route to Review Queue with issues listed    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LAYER 5: Duplicate Detection                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Input: Validated crime object                               â”‚
â”‚ Output: boolean (is duplicate)                              â”‚
â”‚                                                              â”‚
â”‚ âœ“ Check 5.1: Exact URL + headline match                     â”‚
â”‚ âœ“ Check 5.2: Same URL + 90%+ similar headline               â”‚
â”‚ âœ“ Check 5.3: Same date + area + 75%+ similar headline       â”‚
â”‚ âœ“ Check 5.4: Same date + victim age match                   â”‚
â”‚ âœ“ Check 5.5: Same victim name (fuzzy match)                 â”‚
â”‚                                                              â”‚
â”‚ âŒ Duplicate Found: Log and skip, don't add to Production   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LAYER 6: Routing Decision                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Input: Validated, non-duplicate crime                       â”‚
â”‚ Output: Add to Production OR Review Queue                   â”‚
â”‚                                                              â”‚
â”‚ If validation.valid AND confidence â‰¥7:                       â”‚
â”‚   â†’ Geocode â†’ Production Sheet                              â”‚
â”‚                                                              â”‚
â”‚ If validation.valid BUT confidence 1-6:                      â”‚
â”‚   â†’ Geocode â†’ Review Queue (with ambiguities)               â”‚
â”‚                                                              â”‚
â”‚ If !validation.valid:                                        â”‚
â”‚   â†’ Review Queue (with validation issues)                   â”‚
â”‚                                                              â”‚
â”‚ If confidence = 0:                                           â”‚
â”‚   â†’ Skip (mark article as "skipped")                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ Comprehensive Scenario Analysis

### Scenario 1: Perfect Crime Article

**Input:**
- RSS: "Man shot dead in Port of Spain"
- URL: newsday.co.tt/2025/11/09/man-shot-dead-pos
- Content: Focused article about single shooting

**Expected Flow:**
1. âœ… RSS Collection: Valid URL, unique, added as "pending"
2. âœ… Article Fetch: HTTP 200, extracts <article> content, title keywords match 80%
3. âœ… Gemini: Extracts 1 crime, confidence 9
4. âœ… Validation: All fields valid, source_url correct, no non-crime keywords
5. âœ… Duplicate: No duplicates found
6. âœ… Routing: confidence â‰¥7 â†’ Production

**Result:** âœ… Added to Production with high confidence

---

### Scenario 2: Multi-Crime Article

**Input:**
- RSS: "Weekend violence: Three shootings reported"
- URL: trinidadexpress.com/weekend-violence
- Content: Article describes 3 separate shooting incidents

**Expected Flow:**
1. âœ… RSS Collection: Valid, unique
2. âœ… Article Fetch: Extracts article content
3. âœ… Gemini: Extracts 3 crimes (array), confidence 8
4. âœ… Validation (Crime 1): Valid, headline in content âœ…
5. âœ… Validation (Crime 2): Valid, headline in content âœ…
6. âœ… Validation (Crime 3): Valid, headline in content âœ…
7. âœ… Duplicate: None (different headlines despite same URL)
8. âœ… Routing: All 3 crimes â†’ Production

**Result:** âœ… 3 entries added to Production, all with same source URL

---

### Scenario 3: Non-Crime Article (Current Bug!)

**Input:**
- RSS: "President: UN youth programme promotes peace"
- URL: newsday.co.tt/president-un-youth-programme
- Content: Article about youth programme + SIDEBAR with crime headlines

**Current (Broken) Flow:**
1. âœ… RSS Collection: Valid
2. âŒ Article Fetch: Strips ALL HTML, includes sidebar â†’ "...youth programme... Man shot in Williamsville... Vendor injured..."
3. âŒ Gemini: Sees crime text, extracts 3 "crimes", confidence 8
4. âŒ Validation: source_url correct but headline NOT in article content
5. âœ… Duplicate: None
6. âŒ Routing: HIGH confidence â†’ Production âŒ

**Result:** âŒ 3 fake crimes added to Production with wrong context

**Fixed Flow:**
1. âœ… RSS Collection: Valid
2. âœ… Article Fetch (IMPROVED): Extracts only <article> tag content
3. âœ… Gemini: No crime keywords in actual article â†’ confidence 0
4. âœ… Validation: N/A (no crimes extracted)
5. âœ… Routing: Skip, mark "not a crime article"

**Result:** âœ… Correctly identified as non-crime, not added to Production

---

### Scenario 4: Traffic Accident (Should NOT be included)

**Input:**
- RSS: "Vendor injured crossing highway"
- URL: trinidadexpress.com/vendor-injured
- Content: Pedestrian hit by vehicle, not criminal act

**Expected Flow:**
1. âœ… RSS Collection: Valid
2. âœ… Article Fetch: Extracts article content
3. âœ… Gemini: Extracts 1 "crime", type: "Other", confidence 3
4. âŒ Validation: Detects "injured crossing" keyword â†’ validation.valid = false
5. âœ… Routing: !valid â†’ Review Queue

**Result:** âœ… Sent to Review Queue for manual decision (not auto-added to Production)

---

### Scenario 5: Duplicate Crime (Different Sources)

**Input A (Trinidad Express):**
- RSS: "Man, 29, executed in Guapo shooting"
- Content: Josiah Phillip, 29, shot in Guapo

**Input B (Trinidad Newsday - next day):**
- RSS: "Guapo murder victim identified"
- Content: Josiah Phillip, 29, killed in Guapo

**Expected Flow:**
1. âœ… Article A processed â†’ Production
2. âœ… Article B fetched and extracted
3. âœ… Gemini: Extracts 1 crime
4. âœ… Validation: All valid
5. âœ… Duplicate Check:
   - Different URLs âŒ
   - Same date (Nov 7) âœ…
   - Same area (Guapo) âœ…
   - Victim age 29 in both âœ…
   - Headline 75% similar âœ…
   - **DUPLICATE DETECTED**
6. âŒ Routing: Skip, log "duplicate of existing crime"

**Result:** âœ… Duplicate correctly identified, not added again

---

### Scenario 6: Foreign Crime (Should be excluded)

**Input:**
- RSS: "US airstrikes kill three in Caribbean Sea"
- Content: Military action by US forces

**Expected Flow:**
1. âœ… RSS Collection: Valid
2. âœ… Article Fetch: Content extracted
3. âœ… Gemini: Extracts 1 crime, confidence 4
4. âŒ Validation: Detects "airstrike" + "military" keywords â†’ validation.valid = false
5. âœ… Routing: !valid â†’ Review Queue

**Result:** âœ… Flagged for review, not auto-added to Production

---

### Scenario 7: Truncated Gemini Response

**Input:**
- Very long article with 5 crimes

**Expected Flow:**
1. âœ… Article fetched
2. âŒ Gemini: Response truncated (finishReason: MAX_TOKENS)
3. âœ… Truncation Detection: isResponseTruncated() returns true
4. âœ… Partial Parse: Extract what we got (2 crimes)
5. âŒ Validation: confidence lowered to 2, ambiguity added
6. âœ… Routing: Low confidence â†’ Review Queue

**Result:** âœ… Partial crimes sent to Review Queue with "TRUNCATED" flag

---

### Scenario 8: Gemini Safety Filter

**Input:**
- Article with graphic violence description

**Expected Flow:**
1. âœ… Article fetched
2. âŒ Gemini: No candidates returned (safety filter)
3. âœ… Safety Detection: Check responseData.candidates.length === 0
4. âœ… Routing: confidence = 0, ambiguity: "AI safety filter triggered"
5. âœ… Mark: Article status = "needs_manual_review"

**Result:** âœ… Flagged for manual extraction, logged

---

### Scenario 9: Invalid Date in Article

**Input:**
- Article says "crime occurred recently" (vague)

**Expected Flow:**
1. âœ… Article fetched
2. âœ… Gemini: Uses publication date as fallback
3. âœ… Validation: Date within 30 days of publication âœ…
4. âš ï¸ Ambiguity logged: "Date vague, used publication date"
5. âœ… Routing: If confidence â‰¥7 â†’ Production (with ambiguity note)

**Result:** âœ… Added but flagged for possible review

---

### Scenario 10: Geocoding Failure

**Input:**
- Crime in "Rural Trinidad" (too vague)

**Expected Flow:**
1. âœ… All validations pass
2. âœ… Routing: â†’ Production
3. âŒ Geocoding: Can't find "Rural Trinidad", returns null
4. âœ… Fallback: lat/lng = null, plus_code = null, area remains "Rural Trinidad"
5. âœ… Added: Crime added with missing geocoding

**Result:** âœ… Crime added, geocoding can be manually fixed later

---

## ğŸ› ï¸ Implementation Checklist

### Phase 1: Deep Diagnostics (Confirm Root Cause)

- [ ] Add `deepDiagnostics.gs` to Google Apps Script
- [ ] Run `runDeepDiagnostics()`
- [ ] Confirm sidebar contamination percentage
- [ ] Inspect Row 3 content (President article)
- [ ] Verify our hypothesis is correct

**Expected Result:** >30% contamination, confirming sidebar issue

---

### Phase 2: Fix Article Fetcher

- [ ] Create `articleFetcherImproved.gs`
- [ ] Implement smart HTML parsing:
  - Target `<article>` tag first
  - Fallback to `<div class="entry-content">`, `<div class="article-content">`
  - Fallback to `<div id="content">`
  - Last resort: current method
- [ ] Add title keyword matching validation
- [ ] Test with 5 known good articles
- [ ] Test with 3 known contaminated articles
- [ ] Deploy if tests pass

**Success Criteria:**
- Title keyword match >60% for all tested articles
- No crime keywords in non-crime articles

---

### Phase 3: Add Validation Layers

- [ ] Create `validationLayer.gs`
- [ ] Implement `validateArticleFetch()` (Layer 2)
- [ ] Implement `validateGeminiResponse()` (Layer 3)
- [ ] Implement `validateCrimeData()` (Layer 4)
- [ ] Add validation calls to processor.gs
- [ ] Test with known good/bad data

**Success Criteria:**
- All 10 scenarios handled correctly
- Clear error messages for each validation failure

---

### Phase 4: Improve Gemini Prompt

- [ ] Update prompt in geminiClient.gs
- [ ] Add explicit exclusion list
- [ ] Add "DO NOT extract from sidebars" instruction
- [ ] Add source_url prohibition
- [ ] Test with 10 sample articles
- [ ] Verify no non-crime extractions

**Success Criteria:**
- 0% non-crime articles extracted
- Confidence scores more accurate

---

### Phase 5: Strengthen Duplicate Detection

- [ ] Update `isDuplicateCrime()` in processor.gs
- [ ] Add date + area + similarity check
- [ ] Add victim age matching
- [ ] Test with known duplicates from different sources
- [ ] Test with multi-crime articles (should NOT flag as duplicates)

**Success Criteria:**
- True duplicates caught 95%+
- Multi-crime articles NOT flagged as duplicates

---

### Phase 6: Create Testing Framework

- [ ] Create `testFramework.gs`
- [ ] Add unit tests for each validation function
- [ ] Add integration tests for complete flow
- [ ] Add test data samples (good/bad/edge cases)
- [ ] Document expected vs actual results

**Success Criteria:**
- All 10 scenarios have automated tests
- Tests run in <2 minutes
- Clear pass/fail reporting

---

### Phase 7: Build Monitoring Dashboard

- [ ] Create `monitoring.gs`
- [ ] Add daily quality report function
- [ ] Add weekly trend analysis
- [ ] Add alert thresholds (>10% non-crime, >5% duplicates)
- [ ] Email notification on threshold breach

**Success Criteria:**
- Automated daily reports
- Issues caught within 24 hours

---

## ğŸ“ˆ Success Metrics (Final State)

**Layer 1: RSS Collection**
- âœ… 100% valid URLs
- âœ… <2% duplicates

**Layer 2: Article Fetching**
- âœ… 95%+ HTTP 200 success rate
- âœ… 90%+ title keyword match
- âœ… 0% sidebar contamination

**Layer 3: Gemini Extraction**
- âœ… 95%+ valid JSON responses
- âœ… 0% truncation errors
- âœ… 0% non-crime extractions at confidence â‰¥7

**Layer 4: Crime Validation**
- âœ… 95%+ crimes pass all validations
- âœ… 0% crimes with wrong source_url
- âœ… 0% crimes with dates >30 days from publication

**Layer 5: Duplicate Detection**
- âœ… 98%+ true duplicates caught
- âœ… 0% false positives (multi-crime flagged as duplicates)

**Layer 6: Routing**
- âœ… 85%+ crimes go to Production (confidence â‰¥7)
- âœ… 10-15% go to Review Queue
- âœ… 0% non-crimes in Production

**Overall Quality:**
- âœ… 95%+ accuracy (verified crimes in Production)
- âœ… <3% duplicates in Production
- âœ… 0% non-crimes in Production
- âœ… <10% manual review needed per day

---

## ğŸš¦ Traffic Light System

**Daily Quality Check Results:**

ğŸŸ¢ **GREEN (System Healthy)**
- <5% Review Queue items
- 0 non-crimes detected
- <2% duplicates
- 90%+ geocoding success

ğŸŸ¡ **YELLOW (Needs Attention)**
- 5-10% Review Queue items
- 1-2 non-crimes detected
- 2-5% duplicates
- 80-90% geocoding success

ğŸ”´ **RED (Stop and Fix)**
- >10% Review Queue items
- >2 non-crimes detected
- >5% duplicates
- <80% geocoding success

**Action on RED:** Pause triggers, run diagnostics, fix issues, test, resume

---

## ğŸ“ Next Immediate Steps

1. **You run:** `runDeepDiagnostics()` in Google Apps Script
2. **You share:** The log output with me
3. **I confirm:** The sidebar contamination theory
4. **I create:** Improved article fetcher
5. **You test:** New fetcher with 3-5 articles
6. **We iterate:** Until fetcher is solid
7. **Then build:** Validation layers on top of working fetcher

Sound good? Let's confirm the problem first before building the solution.

---

**Last Updated:** November 9, 2025
**Status:** Ready for deep diagnostics
**Next Action:** Run `runDeepDiagnostics()`
